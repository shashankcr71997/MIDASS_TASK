{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "         Date Images  Likes  Retweets  \\\n",
      "0  2019-04-09   None      0         9   \n",
      "1  2019-04-09   None      0        35   \n",
      "2  2019-04-09   None      0        12   \n",
      "3  2019-04-08   None      0        15   \n",
      "4  2019-04-08   None     14         2   \n",
      "5  2019-04-08   None      5         0   \n",
      "6  2019-04-07   None      0         0   \n",
      "7  2019-04-07   None      0         0   \n",
      "8  2019-04-07   None      1         1   \n",
      "9  2019-04-07   None      5         2   \n",
      "\n",
      "                                                Text      Time  \n",
      "0  RT @IIITDelhi: We are delighted to share that ...  16:45:07  \n",
      "1  RT @Harvard: Professor Jelani Nelson founded A...  05:04:27  \n",
      "2  RT @emnlp2019: For anyone interested in submit...  05:04:11  \n",
      "3  RT @multimediaeval: Announcing the 2019 MediaE...  19:38:09  \n",
      "4  Many Congratulations to @midasIIITD student, S...  07:08:12  \n",
      "5  @midasIIITD thanks all students who have appea...  03:27:42  \n",
      "6  @himanchalchandr Meanwhile, complete CV/NLP ta...  14:17:29  \n",
      "7  @sayangdipto123 Submit as per the guideline ag...  14:17:09  \n",
      "8  We request all students whose interview are sc...  11:43:24  \n",
      "9  Other queries: \"none of the Tweeter Apis give ...  06:55:19  \n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "#conda install --prefix {sys.prefix} tweepy\n",
    "#import tweepy\n",
    "#from tweepy.streaming import StreamListener\n",
    "#from tweepy import OAuthHandler\n",
    "#from tweepy import Stream\n",
    "import tweepy\n",
    "import jsonlines\n",
    "import json\n",
    "import pandas as pd\n",
    "import datetime\n",
    "\n",
    "class TweetsAnalyzer:   \n",
    "    consumerAPIKey = \"XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX\" \n",
    "    consumerSecretKey = \"XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX\"\n",
    "    accessToken = \"XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX\"\n",
    "    accessSecret = \"XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.parsedResultDictionary = {'Text' : [], 'Date': [],'Time': [], 'Likes': [], 'Retweets': [], 'Images': []}\n",
    "    \n",
    "    # Helper method to write in file\n",
    "    def writeTweetsInJsonlFile(self, tweets, filePath):\n",
    "        with jsonlines.open(filePath, mode='w') as writer:\n",
    "            for li in tweets:\n",
    "                try:\n",
    "                    writer.write(li._json)\n",
    "                except:\n",
    "                    continue\n",
    "                    \n",
    "    # Helper method for parsing tweets\n",
    "    def jsonlParser(self, tweet):\n",
    "        if 'retweet_count' in tweet:\n",
    "            li = self.parsedResultDictionary['Retweets'] \n",
    "            li.append(tweet['retweet_count'])\n",
    "            self.parsedResultDictionary['Retweets'] = li\n",
    "        else:\n",
    "            li = self.parsedResultDictionary['Retweets']\n",
    "            li.append('-')\n",
    "            self.parsedResultDictionary['Retweets'] = li\n",
    "        if 'favorite_count' in tweet:\n",
    "            li = self.parsedResultDictionary['Likes'] \n",
    "            li.append(tweet['favorite_count'])\n",
    "            self.parsedResultDictionary['Likes'] = li\n",
    "        else:\n",
    "            li = self.parsedResultDictionary['Likes']\n",
    "            li.append('-')\n",
    "            self.parsedResultDictionary['Likes'] = li\n",
    "        if 'created_at' in tweet:        \n",
    "            datetimeParsed = datetime.datetime.strptime(tweet['created_at'], '%a %b %d %H:%M:%S %z %Y')\n",
    "            li = self.parsedResultDictionary['Date'] \n",
    "            li.append(datetimeParsed.date())\n",
    "            self.parsedResultDictionary['Date'] = li        \n",
    "            li = self.parsedResultDictionary['Time'] \n",
    "            li.append(datetimeParsed.time())\n",
    "            self.parsedResultDictionary['Time'] = li\n",
    "        else:\n",
    "            li = self.parsedResultDictionary['Date']\n",
    "            li.append('-')\n",
    "            self.parsedResultDictionary['Date'] = li\n",
    "            li = self.parsedResultDictionary['Time'] \n",
    "            li.append(datetimeParsed.time())\n",
    "            self.parsedResultDictionary['Time'] = li\n",
    "        if 'text' in tweet:\n",
    "            li = self.parsedResultDictionary['Text'] \n",
    "            li.append(tweet['text'])\n",
    "            self.parsedResultDictionary['Text'] = li\n",
    "        else:\n",
    "            li = self.parsedResultDictionary['Text']\n",
    "            li.append('None')\n",
    "            self.parsedResultDictionary['Text'] = li\n",
    "        if 'entites' in tweet:\n",
    "            li = self.parsedResultDictionary['Images'] \n",
    "            media = status.entities.get('media', [])\n",
    "            if(len(media) > 0):\n",
    "                li.append(len(media))\n",
    "            else:\n",
    "                li.append('None')            \n",
    "            self.parsedResultDictionary['Images'] = li\n",
    "        else:\n",
    "            li = self.parsedResultDictionary['Images']\n",
    "            li.append('None')\n",
    "            self.parsedResultDictionary['Images'] = li\n",
    "            \n",
    "        return self.parsedResultDictionary\n",
    "    \n",
    "    # Printing tweets data in tabular form\n",
    "    def printTweetDataFromJsonlFile(self, filePath):\n",
    "        with jsonlines.open(filePath) as reader:\n",
    "            for obj in reader:\n",
    "                tweet = json.loads(json.dumps(obj))\n",
    "                parsedResult = self.jsonlParser(tweet)\n",
    "            \n",
    "        df = pd.DataFrame(parsedResult)\n",
    "        print (df)\n",
    "    \n",
    "    # Fetching 'threshold' (maximum number) tweets by given twitter handle, and writing to given file\n",
    "    def fetchTweetsByTwitterHandleInFile(self, username, threshold, filePath):\n",
    "        # Authorization         \n",
    "        auth = tweepy.OAuthHandler(self.consumerAPIKey, self.consumerSecretKey)\n",
    "        auth.set_access_token(self.accessToken, self.accessSecret)\n",
    "        api = tweepy.API(auth)\n",
    "        tweets = api.user_timeline(id=username, count = 10)\n",
    "        self.writeTweetsInJsonlFile(tweets, filePath)   \n",
    "\n",
    "# Driver code \n",
    "if __name__ == '__main__': \n",
    "    \n",
    "    analyzer = TweetsAnalyzer()\n",
    "    filePath = 'output.jsonl'\n",
    "    threshold = 10\n",
    "    \n",
    "    print ('Loading data...')\n",
    "    ## twitter handle for the user whose tweets are to be extracted in the given file.\n",
    "    analyzer.fetchTweetsByTwitterHandleInFile(\"midasIIITD\", threshold, filePath)\n",
    "    \n",
    "    ## printing tweets in tabular form\n",
    "    analyzer.printTweetDataFromJsonlFile( filePath )\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
